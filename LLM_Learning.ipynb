{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain==0.0.316"
      ],
      "metadata": {
        "id": "s3IJA6jHj5YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai==0.28.1"
      ],
      "metadata": {
        "id": "TbRssv8AoubJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qlw5buO3kxAV",
        "outputId": "06c89cab-9059-496c-8fe0-349602888bd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0.316'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fho_BA0blDFW",
        "outputId": "172fdb5c-ce0f-4512-c979-40dbe10365d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.28.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI()\n",
        "llm.predict(\"How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YoqCY0z2njhw",
        "outputId": "4911b241-1ad1-47ce-da70-12322cd4273a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As an AI, I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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"
      ],
      "metadata": {
        "id": "5TvldtbWsxIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = \"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\""
      ],
      "metadata": {
        "id": "X7JjWQkBt5-Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI # gpt 3 open ai model\n",
        "\n",
        "opean_llm = OpenAI(openai_api_key=key)\n",
        "opean_llm.predict(\"How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3o4IwN0OsU3S",
        "outputId": "b58b1892-f43b-4266-eabe-bce3b12328b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nI'm doing well, thanks for asking!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import chat_models # gpt 3.5 chat gpt\n",
        "chat_model = ChatOpenAI(openai_api_key=key)\n",
        "chat_model.predict(\"How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VXrBSAdFtgve",
        "outputId": "b8f0b187-0b60-4d37-9009-0de90e59fcae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As an AI, I do not have feelings or emotions, but I am here to assist you with any questions or tasks you may have. How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model.predict(\"What was my previous question?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "B01Y4Zo5uGiY",
        "outputId": "eeaf6e1e-f917-45dc-8fb7-19c5ddb89282"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but as an AI language model, I do not have access to personal information about individuals unless it has been shared with me in the course of our conversation. I prioritize user privacy and confidentiality. Therefore, I don't have knowledge about your previous question or any other personal data. I am here to provide information and help with any questions you may have to the best of my abilities.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains"
      ],
      "metadata": {
        "id": "QsZd2bPMuST_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "chain = ConversationChain(llm=chat_model, verbose=True)\n",
        "chain.run(\"How are you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "q2suXsckuMCD",
        "outputId": "5851f707-0fd8-4572-b8f7-228de60dc365"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm doing great, thank you for asking! As an AI, I don't have feelings like humans do, but I'm here and ready to assist you with any questions or tasks you have. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"What was my previous question?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "5G_sHu3jush9",
        "outputId": "6e7d0473-fdf0-418d-bbac-8e3f85145b85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How are you today?\n",
            "AI: I'm doing great, thank you for asking! As an AI, I don't have feelings like humans do, but I'm here and ready to assist you with any questions or tasks you have. How can I help you today?\n",
            "Human: What was my previous question?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your previous question was \"How are you today?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that using `ConversationChain` we can make gpt remember history."
      ],
      "metadata": {
        "id": "MJK0s4w8vDIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "F2UhrtC8xAuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Return all the subcategories of the following category:\n",
        "\n",
        "Category: {category}\n",
        "\n",
        "Subcategories:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"category\"],\n",
        "                        template=template)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvolR4LCvOcn",
        "outputId": "e6f9460d-ba98-4e83-e00d-d72d1091f09f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['category'], template=' \\nReturn all the subcategories of the following category:\\n\\nCategory: {category}\\n\\nSubcategories:\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=prompt,\n",
        "                 verbose=True\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "o97grpX-xtyG",
        "outputId": "6cf31b5b-78ae-4724-fe0c-984d899c5a41"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m \n",
            "Return all the subcategories of the following category:\n",
            "\n",
            "Category: Machine Learning\n",
            "\n",
            "Subcategories:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Supervised Learning\\n2. Unsupervised Learning\\n3. Reinforcement Learning\\n4. Deep Learning\\n5. Natural Language Processing\\n6. Computer Vision\\n7. Transfer Learning\\n8. Bayesian Learning\\n9. Generative Models\\n10. Decision Trees\\n11. Support Vector Machines\\n12. Neural Networks\\n13. Clustering Algorithms\\n14. Dimensionality Reduction\\n15. Regression Algorithms\\n16. Ensemble Methods\\n17. Anomaly Detection\\n18. Recommendation Systems\\n19. Time Series Analysis\\n20. Model Evaluation and Validation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breakdown prompts in to subelements"
      ],
      "metadata": {
        "id": "vPCoS0IZzAIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.async_helpers import sys\n",
        "from langchain.prompts import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate\n",
        ")\n",
        "\n",
        "system_template = \"\"\"\n",
        "You are helpful assistant who generate comma separated list.\n",
        "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
        "ONLY return comma separated list and nothing more!\n",
        "\"\"\"\n",
        "\n",
        "human_template = \"\"\"\n",
        "{category}\n",
        "\"\"\"\n",
        "\n",
        "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    system_message,\n",
        "    human_message\n",
        "])\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=chat_template,\n",
        "                 verbose=True\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "H9oyKN6ly_Z1",
        "outputId": "4bd014b9-687f-45b4-9bcb-0973022ee225"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Machine Learning\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Recommendation Systems, Time Series Analysis, Dimensionality Reduction, Clustering, Classification, Regression, Neural Networks, Support Vector Machines, Decision Trees, Random Forests, Gradient Boosting, Generative Adversarial Networks, Convolutional Neural Networks, Recurrent Neural Networks, Transfer Learning, Model Evaluation, Model Selection, Hyperparameter Tuning, Feature Engineering, Data Preprocessing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Parser\n",
        "\n",
        "making output usable into code"
      ],
      "metadata": {
        "id": "SMXi9t5H1M-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeperatedParser(BaseOutputParser):\n",
        "\n",
        "  def parse(self, text):\n",
        "    output = text.strip().split(',')\n",
        "    output = [o.strip() for o in output]\n",
        "    return output\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=chat_template,\n",
        "                 verbose=True,\n",
        "                 output_parser=CommaSeperatedParser()\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PrqNcC1Oz6",
        "outputId": "d7e5decb-e377-4f9c-adfc-e0ed4537fabb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Machine Learning\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Deep Learning',\n",
              " 'Reinforcement Learning',\n",
              " 'Supervised Learning',\n",
              " 'Unsupervised Learning',\n",
              " 'Natural Language Processing',\n",
              " 'Computer Vision']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [\n",
        "    {'category': 'Food'},\n",
        "    {'category': 'Country'},\n",
        "    {'category': 'Colors'}\n",
        "]  # generating output for multiple inputs\n",
        "\n",
        "response = chain.apply(input_list)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8QWYB4t2RAQ",
        "outputId": "8d3aed3b-7077-48a4-8ea6-b61c88866ce4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Food\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Country\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Colors\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': ['Fruits',\n",
              "   'Vegetables',\n",
              "   'Grains',\n",
              "   'Dairy',\n",
              "   'Meat',\n",
              "   'Seafood',\n",
              "   'Snacks',\n",
              "   'Beverages']},\n",
              " {'text': ['Afghanistan',\n",
              "   'Albania',\n",
              "   'Algeria',\n",
              "   'Andorra',\n",
              "   'Angola',\n",
              "   'Antigua and Barbuda',\n",
              "   'Argentina',\n",
              "   'Armenia',\n",
              "   'Australia',\n",
              "   'Austria',\n",
              "   'Azerbaijan',\n",
              "   'Bahamas',\n",
              "   'Bahrain',\n",
              "   'Bangladesh',\n",
              "   'Barbados',\n",
              "   'Belarus',\n",
              "   'Belgium',\n",
              "   'Belize',\n",
              "   'Benin',\n",
              "   'Bhutan',\n",
              "   'Bolivia',\n",
              "   'Bosnia and Herzegovina',\n",
              "   'Botswana',\n",
              "   'Brazil',\n",
              "   'Brunei',\n",
              "   'Bulgaria',\n",
              "   'Burkina Faso',\n",
              "   'Burundi',\n",
              "   'Cabo Verde',\n",
              "   'Cambodia',\n",
              "   'Cameroon',\n",
              "   'Canada',\n",
              "   'Central African Republic',\n",
              "   'Chad',\n",
              "   'Chile',\n",
              "   'China',\n",
              "   'Colombia',\n",
              "   'Comoros',\n",
              "   'Congo',\n",
              "   'Costa Rica',\n",
              "   'Croatia',\n",
              "   'Cuba',\n",
              "   'Cyprus',\n",
              "   'Czech Republic',\n",
              "   'Denmark',\n",
              "   'Djibouti',\n",
              "   'Dominica',\n",
              "   'Dominican Republic',\n",
              "   'East Timor',\n",
              "   'Ecuador',\n",
              "   'Egypt',\n",
              "   'El Salvador',\n",
              "   'Equatorial Guinea',\n",
              "   'Eritrea',\n",
              "   'Estonia',\n",
              "   'Ethiopia',\n",
              "   'Fiji',\n",
              "   'Finland',\n",
              "   'France',\n",
              "   'Gabon',\n",
              "   'Gambia',\n",
              "   'Georgia',\n",
              "   'Germany',\n",
              "   'Ghana',\n",
              "   'Greece',\n",
              "   'Grenada',\n",
              "   'Guatemala',\n",
              "   'Guinea',\n",
              "   'Guinea-Bissau',\n",
              "   'Guyana',\n",
              "   'Haiti',\n",
              "   'Honduras',\n",
              "   'Hungary',\n",
              "   'Iceland',\n",
              "   'India',\n",
              "   'Indonesia',\n",
              "   'Iran',\n",
              "   'Iraq',\n",
              "   'Ireland',\n",
              "   'Israel',\n",
              "   'Italy',\n",
              "   'Jamaica',\n",
              "   'Japan',\n",
              "   'Jordan',\n",
              "   'Kazakhstan',\n",
              "   'Kenya',\n",
              "   'Kiribati',\n",
              "   'Korea',\n",
              "   'North',\n",
              "   'Korea',\n",
              "   'South',\n",
              "   'Kosovo',\n",
              "   'Kuwait',\n",
              "   'Kyrgyzstan',\n",
              "   'Laos',\n",
              "   'Latvia',\n",
              "   'Lebanon',\n",
              "   'Lesotho',\n",
              "   'Liberia',\n",
              "   'Libya',\n",
              "   'Liechtenstein',\n",
              "   'Lithuania',\n",
              "   'Luxembourg',\n",
              "   'Macedonia',\n",
              "   'Madagascar',\n",
              "   'Malawi',\n",
              "   'Malaysia',\n",
              "   'Maldives',\n",
              "   'Mali',\n",
              "   'Malta',\n",
              "   'Marshall Islands',\n",
              "   'Mauritania',\n",
              "   'Mauritius',\n",
              "   'Mexico',\n",
              "   'Micronesia',\n",
              "   'Moldova',\n",
              "   'Monaco',\n",
              "   'Mongolia',\n",
              "   'Montenegro',\n",
              "   'Morocco',\n",
              "   'Mozambique',\n",
              "   'Myanmar',\n",
              "   'Namibia',\n",
              "   'Nauru',\n",
              "   'Nepal',\n",
              "   'Netherlands',\n",
              "   'New Zealand',\n",
              "   'Nicaragua',\n",
              "   'Niger',\n",
              "   'Nigeria',\n",
              "   'Norway',\n",
              "   'Oman',\n",
              "   'Pakistan',\n",
              "   'Palau',\n",
              "   'Panama',\n",
              "   'Papua New Guinea',\n",
              "   'Paraguay',\n",
              "   'Peru',\n",
              "   'Philippines',\n",
              "   'Poland',\n",
              "   'Portugal',\n",
              "   'Qatar',\n",
              "   'Romania',\n",
              "   'Russia',\n",
              "   'Rwanda',\n",
              "   'Saint Kitts and Nevis',\n",
              "   'Saint Lucia',\n",
              "   'Saint Vincent and the Grenadines',\n",
              "   'Samoa',\n",
              "   'San Marino',\n",
              "   'Sao Tome and Principe',\n",
              "   'Saudi Arabia',\n",
              "   'Senegal',\n",
              "   'Serbia',\n",
              "   'Seychelles',\n",
              "   'Sierra Leone',\n",
              "   'Singapore',\n",
              "   'Slovakia',\n",
              "   'Slovenia',\n",
              "   'Solomon Islands',\n",
              "   'Somalia',\n",
              "   'South Africa',\n",
              "   'South Sudan',\n",
              "   'Spain',\n",
              "   'Sri Lanka',\n",
              "   'Sudan',\n",
              "   'Suriname',\n",
              "   'Swaziland',\n",
              "   'Sweden',\n",
              "   'Switzerland',\n",
              "   'Syria',\n",
              "   'Taiwan',\n",
              "   'Tajikistan',\n",
              "   'Tanzania',\n",
              "   'Thailand',\n",
              "   'Togo',\n",
              "   'Tonga',\n",
              "   'Trinidad and Tobago',\n",
              "   'Tunisia',\n",
              "   'Turkey',\n",
              "   'Turkmenistan',\n",
              "   'Tuvalu',\n",
              "   'Uganda',\n",
              "   'Ukraine',\n",
              "   'United Arab Emirates',\n",
              "   'United Kingdom',\n",
              "   'United States',\n",
              "   'Uruguay',\n",
              "   'Uzbekistan',\n",
              "   'Vanuatu',\n",
              "   'Vatican City',\n",
              "   'Venezuela',\n",
              "   'Vietnam',\n",
              "   'Yemen',\n",
              "   'Zambia',\n",
              "   'Zimbabwe']},\n",
              " {'text': ['red',\n",
              "   'blue',\n",
              "   'green',\n",
              "   'yellow',\n",
              "   'orange',\n",
              "   'purple',\n",
              "   'pink',\n",
              "   'brown',\n",
              "   'black',\n",
              "   'white']}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[2]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31EBmevI22KO",
        "outputId": "f62f5f6a-45f6-49e9-e06e-21be675df68e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red',\n",
              " 'blue',\n",
              " 'green',\n",
              " 'yellow',\n",
              " 'orange',\n",
              " 'purple',\n",
              " 'pink',\n",
              " 'brown',\n",
              " 'black',\n",
              " 'white']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Sequences"
      ],
      "metadata": {
        "id": "pa3u0m9C3VWq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3vsPGdd3XZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}