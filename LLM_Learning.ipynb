{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjA5P_KE6ZCN"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain==0.0.316"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbRssv8AoubJ"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qlw5buO3kxAV",
        "outputId": "af1b0261-d43c-48e0-9459-b4f99e61bda0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.0.316'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import langchain\n",
        "langchain.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fho_BA0blDFW",
        "outputId": "085d3c5a-4180-44c0-ff99-a348326e813d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.28.1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "openai.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YoqCY0z2njhw",
        "outputId": "93f0c4eb-5942-4475-b1c8-d15a374d86a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm an AI language model, so I don't have feelings, but I'm here to help. How can I assist you today?\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = key\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI()\n",
        "llm.predict(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3o4IwN0OsU3S",
        "outputId": "ee0cedc4-b7f3-4595-facc-e73fdad7218d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nI'm doing well, thank you. How about you?\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.llms import OpenAI # gpt 3 open ai model\n",
        "\n",
        "opean_llm = OpenAI(openai_api_key=key)\n",
        "opean_llm.predict(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VXrBSAdFtgve",
        "outputId": "53e4e7bb-aa2a-497c-b1c2-13e10f58c905"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"As an AI, I don't have feelings, but I'm functioning well. Thank you for asking! How can I assist you today?\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import chat_models # gpt 3.5 chat gpt\n",
        "chat_model = ChatOpenAI(openai_api_key=key)\n",
        "chat_model.predict(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "B01Y4Zo5uGiY",
        "outputId": "068f6f13-f263-48dc-d12d-0427b7281c7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry, but as an AI language model, I don't have access to the browsing history or previous questions of users.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_model.predict(\"What was my previous question?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsZd2bPMuST_"
      },
      "source": [
        "## Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "q2suXsckuMCD",
        "outputId": "a13f8758-2cd8-44ed-d674-42fa85d3598e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm an AI, so I don't have emotions, but I'm functioning perfectly and ready to assist you! How can I help you today?\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "chain = ConversationChain(llm=chat_model, verbose=True)\n",
        "chain.run(\"How are you today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "5G_sHu3jush9",
        "outputId": "5e2b29ad-a8c5-451e-ed47-16c5682530f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: How are you today?\n",
            "AI: I'm an AI, so I don't have emotions, but I'm functioning perfectly and ready to assist you! How can I help you today?\n",
            "Human: What was my previous question?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your previous question was \"How are you today?\"'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"What was my previous question?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJK0s4w8vDIW"
      },
      "source": [
        "here we can see that using `ConversationChain` we can make gpt remember history."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2UhrtC8xAuc"
      },
      "source": [
        "## Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvolR4LCvOcn",
        "outputId": "0a72dd2a-580e-44b1-d96b-5877a59ff284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['category'], template=' \\nReturn all the subcategories of the following category:\\n\\nCategory: {category}\\n\\nSubcategories:\\n')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Return all the subcategories of the following category:\n",
        "\n",
        "Category: {category}\n",
        "\n",
        "Subcategories:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"category\"],\n",
        "                        template=template)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "o97grpX-xtyG",
        "outputId": "73d55cb3-b8cf-4792-e01e-571cc03265c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m \n",
            "Return all the subcategories of the following category:\n",
            "\n",
            "Category: Machine Learning\n",
            "\n",
            "Subcategories:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Bayesian Methods\\n- Decision Trees\\n- Support Vector Machines\\n- Neural Networks\\n- Genetic Algorithms\\n- Clustering Algorithms\\n- Dimensionality Reduction\\n- Ensemble Methods\\n- Transfer Learning\\n- Time Series Analysis\\n- Recommender Systems\\n- Anomaly Detection\\n- Reinforcement Learning'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=prompt,\n",
        "                 verbose=True\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPCoS0IZzAIw"
      },
      "source": [
        "Breakdown prompts in to subelements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "H9oyKN6ly_Z1",
        "outputId": "b817b6a4-cc66-4ff0-f6a4-96fbb1d30d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Machine Learning\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Decision Trees, Random Forests, Support Vector Machines, Neural Networks, Clustering, Dimensionality Reduction'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate\n",
        ")\n",
        "\n",
        "system_template = \"\"\"\n",
        "You are helpful assistant who generate comma separated list.\n",
        "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
        "ONLY return comma separated list and nothing more!\n",
        "\"\"\"\n",
        "\n",
        "human_template = \"\"\"\n",
        "{category}\n",
        "\"\"\"\n",
        "\n",
        "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    system_message,\n",
        "    human_message\n",
        "])\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=chat_template,\n",
        "                 verbose=True\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMXi9t5H1M-V"
      },
      "source": [
        "## Output Parser\n",
        "\n",
        "making output usable into code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PrqNcC1Oz6",
        "outputId": "9d27d894-c0b1-407d-8598-9bbc2ed1423d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Supervised Learning',\n",
              " 'Unsupervised Learning',\n",
              " 'Reinforcement Learning',\n",
              " 'Deep Learning',\n",
              " 'Natural Language Processing',\n",
              " 'Computer Vision',\n",
              " 'Recommendation Systems']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeperatedParser(BaseOutputParser):\n",
        "\n",
        "  def parse(self, text):\n",
        "    output = text.strip().split(',')\n",
        "    output = [o.strip() for o in output]\n",
        "    return output\n",
        "\n",
        "chain = LLMChain(llm=chat_model,\n",
        "                 prompt=chat_template,\n",
        "                 verbose=True,\n",
        "                 output_parser=CommaSeperatedParser()\n",
        "                 )\n",
        "chain.run(\"Machine Learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8QWYB4t2RAQ",
        "outputId": "c4a5569f-8660-4540-e8a3-0594c05e4a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Food\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Country\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "You are helpful assistant who generate comma separated list.\n",
            "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
            "ONLY return comma separated list and nothing more!\n",
            "\n",
            "Human: \n",
            "Colors\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'text': ['Fruits', 'Vegetables', 'Meat', 'Dairy', 'Grains']},\n",
              " {'text': ['Afghanistan',\n",
              "   'Albania',\n",
              "   'Algeria',\n",
              "   'Andorra',\n",
              "   'Angola',\n",
              "   'Antigua and Barbuda',\n",
              "   'Argentina',\n",
              "   'Armenia',\n",
              "   'Australia',\n",
              "   'Austria',\n",
              "   'Azerbaijan',\n",
              "   'Bahamas',\n",
              "   'Bahrain',\n",
              "   'Bangladesh',\n",
              "   'Barbados',\n",
              "   'Belarus',\n",
              "   'Belgium',\n",
              "   'Belize',\n",
              "   'Benin',\n",
              "   'Bhutan',\n",
              "   'Bolivia',\n",
              "   'Bosnia and Herzegovina',\n",
              "   'Botswana',\n",
              "   'Brazil',\n",
              "   'Brunei',\n",
              "   'Bulgaria',\n",
              "   'Burkina Faso',\n",
              "   'Burundi',\n",
              "   'Cabo Verde',\n",
              "   'Cambodia',\n",
              "   'Cameroon',\n",
              "   'Canada',\n",
              "   'Central African Republic',\n",
              "   'Chad',\n",
              "   'Chile',\n",
              "   'China',\n",
              "   'Colombia',\n",
              "   'Comoros',\n",
              "   'Congo',\n",
              "   'Costa Rica',\n",
              "   'Croatia',\n",
              "   'Cuba',\n",
              "   'Cyprus',\n",
              "   'Czech Republic',\n",
              "   'Denmark',\n",
              "   'Djibouti',\n",
              "   'Dominica',\n",
              "   'Dominican Republic',\n",
              "   'East Timor',\n",
              "   'Ecuador',\n",
              "   'Egypt',\n",
              "   'El Salvador',\n",
              "   'Equatorial Guinea',\n",
              "   'Eritrea',\n",
              "   'Estonia',\n",
              "   'Eswatini',\n",
              "   'Ethiopia',\n",
              "   'Fiji',\n",
              "   'Finland',\n",
              "   'France',\n",
              "   'Gabon',\n",
              "   'Gambia',\n",
              "   'Georgia',\n",
              "   'Germany',\n",
              "   'Ghana',\n",
              "   'Greece',\n",
              "   'Grenada',\n",
              "   'Guatemala',\n",
              "   'Guinea',\n",
              "   'Guinea-Bissau',\n",
              "   'Guyana',\n",
              "   'Haiti',\n",
              "   'Honduras',\n",
              "   'Hungary',\n",
              "   'Iceland',\n",
              "   'India',\n",
              "   'Indonesia',\n",
              "   'Iran',\n",
              "   'Iraq',\n",
              "   'Ireland',\n",
              "   'Israel',\n",
              "   'Italy',\n",
              "   'Jamaica',\n",
              "   'Japan',\n",
              "   'Jordan',\n",
              "   'Kazakhstan',\n",
              "   'Kenya',\n",
              "   'Kiribati',\n",
              "   'Korea',\n",
              "   'North',\n",
              "   'Korea',\n",
              "   'South',\n",
              "   'Kosovo',\n",
              "   'Kuwait',\n",
              "   'Kyrgyzstan',\n",
              "   'Laos',\n",
              "   'Latvia',\n",
              "   'Lebanon',\n",
              "   'Lesotho',\n",
              "   'Liberia',\n",
              "   'Libya',\n",
              "   'Liechtenstein',\n",
              "   'Lithuania',\n",
              "   'Luxembourg',\n",
              "   'Madagascar',\n",
              "   'Malawi',\n",
              "   'Malaysia',\n",
              "   'Maldives',\n",
              "   'Mali',\n",
              "   'Malta',\n",
              "   'Marshall Islands',\n",
              "   'Mauritania',\n",
              "   'Mauritius',\n",
              "   'Mexico',\n",
              "   'Micronesia',\n",
              "   'Moldova',\n",
              "   'Monaco',\n",
              "   'Mongolia',\n",
              "   'Montenegro',\n",
              "   'Morocco',\n",
              "   'Mozambique',\n",
              "   'Myanmar',\n",
              "   'Namibia',\n",
              "   'Nauru',\n",
              "   'Nepal',\n",
              "   'Netherlands',\n",
              "   'New Zealand',\n",
              "   'Nicaragua',\n",
              "   'Niger',\n",
              "   'Nigeria',\n",
              "   'North Macedonia',\n",
              "   'Norway',\n",
              "   'Oman',\n",
              "   'Pakistan',\n",
              "   'Palau',\n",
              "   'Panama',\n",
              "   'Papua New Guinea',\n",
              "   'Paraguay',\n",
              "   'Peru',\n",
              "   'Philippines',\n",
              "   'Poland',\n",
              "   'Portugal',\n",
              "   'Qatar',\n",
              "   'Romania',\n",
              "   'Russia',\n",
              "   'Rwanda',\n",
              "   'Saint Kitts and Nevis',\n",
              "   'Saint Lucia',\n",
              "   'Saint Vincent and the Grenadines',\n",
              "   'Samoa',\n",
              "   'San Marino',\n",
              "   'Sao Tome and Principe',\n",
              "   'Saudi Arabia',\n",
              "   'Senegal',\n",
              "   'Serbia',\n",
              "   'Seychelles',\n",
              "   'Sierra Leone',\n",
              "   'Singapore',\n",
              "   'Slovakia',\n",
              "   'Slovenia',\n",
              "   'Solomon Islands',\n",
              "   'Somalia',\n",
              "   'South Africa',\n",
              "   'South Sudan',\n",
              "   'Spain',\n",
              "   'Sri Lanka',\n",
              "   'Sudan',\n",
              "   'Suriname',\n",
              "   'Sweden',\n",
              "   'Switzerland',\n",
              "   'Syria',\n",
              "   'Taiwan',\n",
              "   'Tajikistan',\n",
              "   'Tanzania',\n",
              "   'Thailand',\n",
              "   'Togo',\n",
              "   'Tonga',\n",
              "   'Trinidad and Tobago',\n",
              "   'Tunisia',\n",
              "   'Turkey',\n",
              "   'Turkmenistan',\n",
              "   'Tuvalu',\n",
              "   'Uganda',\n",
              "   'Ukraine',\n",
              "   'United Arab Emirates',\n",
              "   'United Kingdom',\n",
              "   'United States',\n",
              "   'Uruguay',\n",
              "   'Uzbekistan',\n",
              "   'Vanuatu',\n",
              "   'Vatican City',\n",
              "   'Venezuela',\n",
              "   'Vietnam',\n",
              "   'Yemen',\n",
              "   'Zambia',\n",
              "   'Zimbabwe']},\n",
              " {'text': ['Red',\n",
              "   'Blue',\n",
              "   'Green',\n",
              "   'Yellow',\n",
              "   'Orange',\n",
              "   'Purple',\n",
              "   'Pink',\n",
              "   'Brown',\n",
              "   'Black',\n",
              "   'White']}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_list = [\n",
        "    {'category': 'Food'},\n",
        "    {'category': 'Country'},\n",
        "    {'category': 'Colors'}\n",
        "]  # generating output for multiple inputs\n",
        "\n",
        "response = chain.apply(input_list)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31EBmevI22KO",
        "outputId": "420229f2-48fe-42c2-850c-403ab54e0810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Red',\n",
              " 'Blue',\n",
              " 'Green',\n",
              " 'Yellow',\n",
              " 'Orange',\n",
              " 'Purple',\n",
              " 'Pink',\n",
              " 'Brown',\n",
              " 'Black',\n",
              " 'White']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[2]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa3u0m9C3VWq"
      },
      "source": [
        "## Simple Sequences\n",
        "\n",
        "pipe different chains together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3vsPGdd3XZc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
